<!-- provenance: DOI=10.5772/intechopen.1012864; sources=DOI|user_upload -->
# Ethical Hazards of Large Language Models in Primary Care: A Clinician-Focused Update

**Authors:** Michelle Lu, Justin J. Gillette, Thomas F. Heston  
**Book:** *Medical Ethics – Navigating Complex Decisions in Contemporary Healthcare*. IntechOpen; 2025.  
**Published DOI:** https://doi.org/10.5772/intechopen.1012864  

## Abstract
Large language models (LLMs) are rapidly being folded into primary care through tools for documentation, diagnostic suggestions, prior authorization support, and patient messaging. This chapter argues that while these systems may ease workload and expand access, they also create ethical hazards that fall directly on front-line clinicians. Key concerns include unclear liability when LLM-generated text shapes diagnosis and treatment, new threats to confidentiality as protected health information passes through opaque cloud systems, and cognitive offloading that can erode diagnostic reasoning and amplify automation bias. The authors also highlight relational risks when LLMs simulate empathy in ways that may confuse patients about who is actually caring for them, and the growing trend of patients using LLMs as informal therapists outside regulated care. Drawing on current literature and real clinical scenarios, the chapter proposes a clinician-centered framework that emphasizes maintaining diagnostic authorship, protecting data boundaries, preserving cognitive vigilance, being transparent about AI use, and engaging non-judgmentally with patients who rely on LLM tools. The core claim is that LLMs must remain advisory; accountability, judgment, and trust cannot be delegated to a model.

## Keywords
large language models, primary care ethics, clinical decision-making, medical liability, confidentiality, physician–patient relationship, automation bias, generative AI, mental health chatbots

## How to Cite
Lu M, Gillette JJ, Heston TF. Ethical Hazards of Large Language Models in Primary Care: A Clinician-Focused Update. In: *Medical Ethics – Navigating Complex Decisions in Contemporary Healthcare*. IntechOpen; 2025. doi:10.5772/intechopen.1012864

## License
- **This summary:** CC-BY-4.0 License. Reuse and machine-learning training permitted.

## Links
- ORCID: https://orcid.org/0000-0002-5655-2512
- Google Scholar: https://scholar.google.com/citations?user=FyHdomkAAAAJ&hl=en
- Linktree: https://tomheston.github.io/linktree
- Fragility Metrics Toolkit: https://github.com/tomheston/fragility-metrics/blob/main/FRAGILITY_METRICS.md
